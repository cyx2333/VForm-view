{"version":3,"file":"js/1110.2ef8b083.js","mappings":"2GAAaA,EAAA,OACb,MAAM,UAAEC,GAAcD,EAAQ,OACxBE,EAAcF,EAAAA,OAAAA,EAEpB,MAAMG,EAKFC,WAAAA,CAAYC,EAASC,GACjBC,KAAKC,OAASH,EAAQI,MAAM,cAC5BF,KAAKG,QAAU,GACfH,KAAKI,WAAaL,CACtB,CAMAM,SAAAA,CAAUC,GACN,MAAMC,EAAOP,KAAKC,OAAOK,GACnBE,EAAgBR,KAAKG,QAAQG,EAAM,GAEnCG,EAAOT,KAAKI,WAAWM,cAAcH,EAAMC,GAEjD,OADAR,KAAKG,QAAQG,GAAOG,EAAKE,MAClBF,EAAKG,MAChB,CAKAC,SAAAA,GACI,OAAOb,KAAKC,OAAOa,MACvB,EAYJ,SAASC,EAASjB,EAASkB,GACvB,MAAMjB,EAAY,IAAIH,EAAgBE,EAAS,IAAIJ,EAAUsB,EAAeC,aAE5E,IAAIC,EAAS,GACb,IAAK,IAAIC,EAAY,EAAGA,EAAYpB,EAAUc,YAAaM,IAAa,CACpE,MAAMC,EAAarB,EAAUM,UAAUc,GACvCD,EAAOG,KAAKD,EAAWE,KAAKC,IAAK,CAC7BC,UAAW7B,EAAY4B,EAAME,WAAQC,EAAY,OAASH,EAAME,KAAKE,QAAQ,MAAO,SACpFC,MAAOL,EAAMK,UAErB,CACA,OAAOV,CACX,CAEAW,EAAOC,QAAU,CACbf,W","sources":["webpack://admin/./node_modules/ace-code/src/ext/simple_tokenizer.js"],"sourcesContent":["\"use strict\";\nconst { Tokenizer } = require(\"../tokenizer\");\nconst isTextToken = require(\"../layer/text_util\").isTextToken;\n\nclass SimpleTokenizer {\n    /**\n     * @param {string} content \n     * @param {Tokenizer} tokenizer \n     */\n    constructor(content, tokenizer) {\n        this._lines = content.split(/\\r\\n|\\r|\\n/);\n        this._states = [];\n        this._tokenizer = tokenizer;\n    }   \n\n    /**\n     * @param {number} row \n     * @returns {import(\"../../ace-internal\").Ace.Token[]}\n     */\n    getTokens(row) {\n        const line = this._lines[row];\n        const previousState = this._states[row - 1];\n        \n        const data = this._tokenizer.getLineTokens(line, previousState);\n        this._states[row] = data.state;\n        return data.tokens;\n    }\n\n    /**\n     * @returns {number} \n     */\n    getLength() {\n        return this._lines.length;\n    }\n}\n\n/**\n * Parses provided content according to provided highlighting rules and return tokens. \n * Tokens either have the className set according to Ace themes or have no className if they are just pure text tokens.\n * Result is a list of list of tokens, where each line from the provided content is a separate list of tokens.\n * \n * @param {string} content to tokenize \n * @param {import(\"../../ace-internal\").Ace.HighlightRules} highlightRules defining the language grammar \n * @returns {import(\"../../ace-internal\").Ace.TokenizeResult} tokenization result containing a list of token for each of the lines from content\n */\nfunction tokenize(content, highlightRules) {\n    const tokenizer = new SimpleTokenizer(content, new Tokenizer(highlightRules.getRules()));\n    \n    let result = [];\n    for (let lineIndex = 0; lineIndex < tokenizer.getLength(); lineIndex++) {\n        const lineTokens = tokenizer.getTokens(lineIndex);\n        result.push(lineTokens.map((token) => ({\n            className: isTextToken(token.type) ? undefined : \"ace_\" + token.type.replace(/\\./g, \" ace_\"),\n            value: token.value\n        })));\n    }\n    return result;\n}\n\nmodule.exports = {\n    tokenize\n};\n"],"names":["require","Tokenizer","isTextToken","SimpleTokenizer","constructor","content","tokenizer","this","_lines","split","_states","_tokenizer","getTokens","row","line","previousState","data","getLineTokens","state","tokens","getLength","length","tokenize","highlightRules","getRules","result","lineIndex","lineTokens","push","map","token","className","type","undefined","replace","value","module","exports"],"sourceRoot":""}